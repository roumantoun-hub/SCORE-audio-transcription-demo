{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install"
      ],
      "metadata": {
        "id": "f-ddBiFmkVAt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3B252W33VHDC"
      },
      "outputs": [],
      "source": [
        "!pip install music21 --quiet\n",
        "!pip install pretty_midi --quiet\n",
        "!pip install scikit-learn --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "pH5W5m7JkZVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import music21 as m21\n",
        "import pretty_midi\n",
        "import numpy as np\n",
        "import os\n",
        "import collections\n",
        "import math\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from collections import OrderedDict"
      ],
      "metadata": {
        "id": "JOt3CbFZkSfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ],
      "metadata": {
        "id": "pYo6CyxDkbno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_bpm_and_extract_features(filepath):\n",
        "    \"\"\"\n",
        "    Analyzes a symbolic music file (e.g., MIDI) to detect BPM and\n",
        "    prepare the basic data structures for feature extraction.\n",
        "\n",
        "    Args:\n",
        "        filepath (str): The path to the MIDI or MusicXML file.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (detected_bpm, note_data_stream, total_duration_quarter_notes, full_score)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 1. Parse the file using music21\n",
        "        score = m21.converter.parse(filepath)\n",
        "        # Use .flatten() to get all notes in one stream (fixes the warning)\n",
        "        note_data_stream = score.flatten().notesAndRests\n",
        "\n",
        "        print(f\"Successfully parsed file: {os.path.basename(filepath)}\")\n",
        "\n",
        "        # --- 1.2 BPM Detection ---\n",
        "\n",
        "        # A. Metadata Extraction (The easiest way)\n",
        "        tempo = score.flat.getElementsByClass(m21.tempo.MetronomeMark)\n",
        "        detected_bpm = None\n",
        "\n",
        "        if tempo:\n",
        "            # Get the value from the first detected tempo mark\n",
        "            detected_bpm = tempo[0].number\n",
        "            print(f\"  -> BPM (from Metadata): {detected_bpm:.2f}\")\n",
        "        else:\n",
        "            # B. Onset Periodicity Analysis (If no metadata is found)\n",
        "            estimated_tempo = m21.analysis.simple.getEstimatedTempo(score)\n",
        "            detected_bpm = estimated_tempo.number\n",
        "            print(f\"  -> BPM (Estimated using simple analysis): {detected_bpm:.2f}\")\n",
        "\n",
        "        # --- Data Preparation for other Features ---\n",
        "\n",
        "        # Count notes/chords and calculate total duration for Note Density\n",
        "        note_count = len([e for e in note_data_stream if e.isNote or e.isChord])\n",
        "\n",
        "        # Calculate the total duration of the piece in quarter lengths (beats)\n",
        "        total_duration_quarter_notes = score.duration.quarterLength\n",
        "\n",
        "        print(f\"  -> Total notes/chords extracted: {note_count}\")\n",
        "\n",
        "        return detected_bpm, note_data_stream, total_duration_quarter_notes, score\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during analysis: {e}\")\n",
        "        return None, None, 0, None\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# STEP 2: HARMONIC AND PITCH FEATURES (Helper Functions)\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "def get_pitch_features(note_data_stream):\n",
        "    \"\"\"\n",
        "    Calculates features related to melody and pitch range.\n",
        "    \"\"\"\n",
        "    pitch_values = []\n",
        "\n",
        "    for element in note_data_stream:\n",
        "        if element.isNote:\n",
        "            pitch_values.append(element.pitch.midi)\n",
        "        elif element.isChord:\n",
        "            for p in element.pitches:\n",
        "                pitch_values.append(p.midi)\n",
        "\n",
        "    if not pitch_values:\n",
        "        return {'average_pitch': 0, 'pitch_range': 0}\n",
        "\n",
        "    average_pitch = np.mean(pitch_values)\n",
        "    pitch_range = np.max(pitch_values) - np.min(pitch_values)\n",
        "\n",
        "    return {\n",
        "        'average_pitch': average_pitch,\n",
        "        'pitch_range': pitch_range\n",
        "    }\n",
        "\n",
        "def get_harmonic_features(score):\n",
        "    \"\"\"\n",
        "    Calculates features related to tonality, key, and consonance (chord complexity).\n",
        "    \"\"\"\n",
        "    # 1. Tonal Center (Key Detection)\n",
        "    key_analysis = score.analyze('key')\n",
        "\n",
        "    key_name = key_analysis.name\n",
        "    key_stability = key_analysis.correlationCoefficient\n",
        "    mode = 1 if key_analysis.mode == 'major' else 0 # 1 for Major, 0 for Minor/Other\n",
        "\n",
        "    return {\n",
        "        # We don't return key_name because ML models need numbers, not strings\n",
        "        'key_stability': key_stability,\n",
        "        'mode_major': mode\n",
        "    }\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# STEP 3: RHYTHMIC FEATURES (Helper Function)\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "def get_rhythmic_features(note_data_stream, total_duration_quarter_notes):\n",
        "    \"\"\"\n",
        "    Calculates features related to rhythm, tempo, and note density.\n",
        "    \"\"\"\n",
        "    note_durations = []\n",
        "\n",
        "    # Collect all note/chord durations\n",
        "    for element in note_data_stream:\n",
        "        if element.isNote or element.isChord:\n",
        "            note_durations.append(element.duration.quarterLength)\n",
        "\n",
        "    if not note_durations:\n",
        "        return {'note_density': 0, 'rhythm_variety': 0}\n",
        "\n",
        "    # 1. Note Density (Notes per quarter note/beat)\n",
        "    note_count = len(note_durations)\n",
        "    note_density = note_count / total_duration_quarter_notes if total_duration_quarter_notes > 0 else 0\n",
        "\n",
        "    # 2. Rhythm Variety (Entropy of Durations)\n",
        "    duration_counts = collections.Counter(note_durations)\n",
        "    total_notes = len(note_durations)\n",
        "\n",
        "    rhythm_variety = 0\n",
        "    for count in duration_counts.values():\n",
        "        probability = count / total_notes\n",
        "        rhythm_variety -= probability * math.log2(probability)\n",
        "\n",
        "    return {\n",
        "        'note_density': note_density,\n",
        "        'rhythm_variety': rhythm_variety\n",
        "    }\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# STEP 4: DATA CONSOLIDATION AND PREPARATION\n",
        "# This function combines all feature extractions into one, clean dictionary.\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "def extract_all_features(filepath):\n",
        "    \"\"\"\n",
        "    Runs all feature extraction methods and combines the results.\n",
        "\n",
        "    Args:\n",
        "        filepath (str): The path to the MIDI file.\n",
        "\n",
        "    Returns:\n",
        "        dict: A single dictionary containing all numeric features.\n",
        "    \"\"\"\n",
        "    # Step 1: Get core data\n",
        "    bpm_result, data_stream, total_duration, full_score = detect_bpm_and_extract_features(filepath)\n",
        "\n",
        "    if bpm_result is None or data_stream is None or total_duration == 0 or full_score is None:\n",
        "        print(\"Error: Core data extraction failed or file is empty.\")\n",
        "        return None\n",
        "\n",
        "    # Initialize the main feature dictionary with BPM\n",
        "    all_features = {'bpm': bpm_result}\n",
        "\n",
        "    # Step 2: Pitch and Harmonic Features\n",
        "    pitch_features = get_pitch_features(data_stream)\n",
        "    harmonic_features = get_harmonic_features(full_score)\n",
        "    all_features.update(pitch_features)\n",
        "    all_features.update(harmonic_features)\n",
        "\n",
        "    # Step 3: Rhythmic Features\n",
        "    rhythmic_features = get_rhythmic_features(data_stream, total_duration)\n",
        "    all_features.update(rhythmic_features)\n",
        "\n",
        "    return all_features\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# FINAL EXECUTION BLOCK (Updated to run all steps)\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "# 1. <<< --- CHANGE THIS LINE FOR EVERY NEW FILE --- >>>\n",
        "#    Replace 'ceremony_basic_pitch.mid' with the name of your new uploaded MIDI file.\n",
        "midi_file_path = 'sound2.mid' # YOUR NEW FILE GOES HERE\n",
        "\n",
        "# Create a mock file for demonstration if running without a real file uploaded\n",
        "if not os.path.exists(midi_file_path):\n",
        "    print(\"Creating a mock MIDI file for demonstration...\")\n",
        "    mock_score = m21.stream.Score()\n",
        "    mock_score.append(m21.key.Key('C', 'major'))\n",
        "    mock_score.insert(m21.tempo.MetronomeMark(number=120))\n",
        "    part = m21.stream.Part()\n",
        "    part.append(m21.note.Note('C4', quarterLength=1.0))\n",
        "    part.append(m21.note.Note('E4', quarterLength=0.5))\n",
        "    part.append(m21.note.Note('F4', quarterLength=0.5))\n",
        "    part.append(m21.chord.Chord(['G4', 'C5'], quarterLength=2.0))\n",
        "    mock_score.append(part)\n",
        "    mock_score.write('midi', fp=midi_file_path)\n",
        "    print(f\"Mock file '{midi_file_path}' created with BPM 120 (C Major).\")\n",
        "\n",
        "\n",
        "# Run the full feature extraction pipeline\n",
        "final_features = extract_all_features(midi_file_path)\n",
        "\n",
        "if final_features:\n",
        "    # Add the file name to the dictionary for tracking in the next cell\n",
        "    final_features['original_file'] = midi_file_path\n",
        "\n",
        "    # 2. <<< --- NEW: SET GLOBAL VARIABLE FOR THE NEXT CELL --- >>>\n",
        "    # This makes the features available to the 'song_recommender.py' script.\n",
        "    global LAST_ANALYZED_FEATURES\n",
        "    LAST_ANALYZED_FEATURES = final_features # Store the results globally\n",
        "\n",
        "    print(\"\\n\\n####################################################\")\n",
        "    print(\"FINAL CONSOLIDATED FEATURES (READY FOR ML):\")\n",
        "    for key, value in final_features.items():\n",
        "        if isinstance(value, float):\n",
        "            print(f\"- {key.replace('_', ' ').title():<20}: {value:.4f}\")\n",
        "        else:\n",
        "            # Only print the original file path if it's not a float\n",
        "            if key == 'original_file':\n",
        "                 print(f\"- {key.replace('_', ' ').title():<20}: {value} (USED FOR ANALYSIS)\")\n",
        "            else:\n",
        "                 print(f\"- {key.replace('_', ' ').title():<20}: {value}\")\n",
        "    print(\"####################################################\")\n",
        "\n",
        "    print(f\"\\nFeatures for '{midi_file_path}' successfully stored globally.\")\n",
        "    print(\"Now run the 'Song Recommendation Engine' cell to get recommendations.\")"
      ],
      "metadata": {
        "id": "N87YGG27koGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "REAL_SONG_LIBRARY = [\n",
        "    # Classical/Chill Cluster (Low BPM, High Stability, Low Density)\n",
        "    (\"Clair de Lune\", \"Debussy\", 60, 65.0, 35.0, 0.95, 0, 0.7, 1.2),\n",
        "    (\"Gymnopédie No. 1\", \"Satie\", 80, 50.0, 20.0, 0.90, 0, 0.5, 1.0),\n",
        "    (\"The Four Seasons: Spring\", \"Vivaldi\", 130, 70.0, 45.0, 0.88, 1, 2.8, 3.5),\n",
        "    (\"Canon in D\", \"Pachelbel\", 60, 55.0, 25.0, 0.98, 1, 1.0, 1.5),\n",
        "    (\"Für Elise\", \"Beethoven\", 130, 68.0, 38.0, 0.85, 0, 1.5, 2.2),\n",
        "\n",
        "    # Pop/Rock Cluster (Mid BPM, Mid Range, Major Mode)\n",
        "    (\"Can't Stop The Feeling!\", \"Timberlake\", 113, 56.0, 30.0, 0.70, 1, 2.5, 2.0),\n",
        "    (\"Imagine\", \"Lennon\", 75, 52.0, 25.0, 0.80, 1, 1.0, 1.5),\n",
        "    (\"A Thousand Miles\", \"Carlton\", 95, 60.0, 30.0, 0.78, 1, 1.8, 1.8),\n",
        "    (\"Happy\", \"Pharrell Williams\", 160, 54.0, 28.0, 0.65, 1, 3.0, 2.5),\n",
        "    (\"Shape of You\", \"Ed Sheeran\", 96, 50.0, 22.0, 0.72, 0, 2.2, 1.6),\n",
        "    (\"Blinding Lights\", \"The Weeknd\", 171, 58.0, 35.0, 0.60, 0, 3.5, 3.0),\n",
        "\n",
        "    # Jazz/Electronic/Fast Cluster (High BPM, High Variety/Density, Lower Stability)\n",
        "    (\"Take Five\", \"Dave Brubeck\", 170, 60.5, 45.0, 0.50, 0, 3.5, 4.0),\n",
        "    (\"So What\", \"Miles Davis\", 140, 65.0, 55.0, 0.55, 1, 3.0, 4.5),\n",
        "    (\"Rhapsody in Blue\", \"Gershwin\", 100, 72.0, 50.0, 0.65, 1, 2.8, 3.8),\n",
        "    (\"Strobe\", \"deadmau5\", 128, 55.0, 30.0, 0.58, 0, 3.2, 3.2),\n",
        "    (\"Levels\", \"Avicii\", 126, 62.0, 40.0, 0.62, 1, 3.8, 3.5),\n",
        "    (\"Aerodynamic\", \"Daft Punk\", 120, 68.0, 42.0, 0.53, 0, 4.0, 4.2),\n",
        "\n",
        "    # World/Diverse Cluster\n",
        "    (\"Libertango\", \"Piazzolla\", 120, 65.0, 35.0, 0.70, 0, 2.5, 3.0),\n",
        "    (\"Oye Como Va\", \"Santana\", 128, 55.0, 30.0, 0.68, 1, 3.0, 3.5),\n",
        "    (\"The Girl from Ipanema\", \"Jobim\", 115, 58.0, 25.0, 0.75, 1, 1.5, 2.0)\n",
        "]\n",
        "\n",
        "# --- Step 1: Define the Recommendation Model Function ---\n",
        "\n",
        "def recommend_songs(input_features, k=5):\n",
        "    \"\"\"\n",
        "    Uses the K-Nearest Neighbors (KNN) algorithm to find the 'k' most\n",
        "    musically similar songs to the input song based on their features.\n",
        "    \"\"\"\n",
        "    # Exclude the filename from the feature vector calculation\n",
        "    song_name = input_features.get('original_file', 'The Analyzed Song')\n",
        "\n",
        "    # 1. Define the Feature Columns (MUST match the order in the library list)\n",
        "    FEATURE_COLUMNS = [\n",
        "        'bpm', 'average_pitch', 'pitch_range',\n",
        "        'key_stability', 'mode_major',\n",
        "        'note_density', 'rhythm_variety'\n",
        "    ]\n",
        "\n",
        "    # 2. Extract Features and Metadata from the Real Song Library\n",
        "    X_library = np.array([song[2:] for song in REAL_SONG_LIBRARY])\n",
        "    Y_metadata = [(song[0], song[1]) for song in REAL_SONG_LIBRARY] # (Title, Artist)\n",
        "\n",
        "    print(f\"\\n--- Starting Song Recommendation Engine (Step 5) for: {song_name} ---\")\n",
        "    print(f\"--- Library Size: {len(Y_metadata)} real songs loaded ---\")\n",
        "\n",
        "\n",
        "    # 3. Scale the Data\n",
        "    scaler = StandardScaler()\n",
        "    X_library_scaled = scaler.fit_transform(X_library)\n",
        "\n",
        "    # 4. Prepare the New Song's Data (Your uploaded file)\n",
        "    input_vector = [input_features[col] for col in FEATURE_COLUMNS]\n",
        "    X_input_scaled = scaler.transform([input_vector]) # Scale the new song vector\n",
        "\n",
        "    # 5. Find Nearest Neighbors\n",
        "    # We use NearestNeighbors to find the closest points in musical space\n",
        "    nn_model = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "    nn_model.fit(X_library_scaled)\n",
        "\n",
        "    # Calculate distances and indices of the nearest neighbors\n",
        "    # We use k for n_neighbors, as we assume your uploaded song is NOT in the library\n",
        "    distances, indices = nn_model.kneighbors(X_input_scaled)\n",
        "\n",
        "    # 6. Process Recommendations\n",
        "    recommendations = []\n",
        "\n",
        "    for i in range(len(indices[0])):\n",
        "        song_index = indices[0][i]\n",
        "        distance = distances[0][i]\n",
        "\n",
        "        if song_index < len(Y_metadata):\n",
        "            title, artist = Y_metadata[song_index]\n",
        "\n",
        "            # Simple conversion to a 0-100 score. Lower distance (closer match) means higher score.\n",
        "            # Using a scale factor of 8 helps keep the scores realistic for this dataset size.\n",
        "            similarity_score = max(0, 100 - (distance * 8))\n",
        "\n",
        "            recommendations.append({\n",
        "                'title': title,\n",
        "                'artist': artist,\n",
        "                'similarity_score': similarity_score\n",
        "            })\n",
        "\n",
        "    # Sort by the highest similarity score (should already be sorted, but safer to confirm)\n",
        "    recommendations.sort(key=lambda x: x['similarity_score'], reverse=True)\n",
        "\n",
        "    return recommendations[:k] # Return only the top 'k' recommendations\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# FINAL EXECUTION BLOCK\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "# 1. CHECK FOR GLOBAL FEATURES\n",
        "if 'LAST_ANALYZED_FEATURES' in globals():\n",
        "    your_song_features = LAST_ANALYZED_FEATURES\n",
        "    file_analyzed = your_song_features.get('original_file', 'The Last Analyzed Song')\n",
        "    print(f\"Successfully loaded features for: {file_analyzed}\")\n",
        "else:\n",
        "    # If the feature extractor wasn't run, use a generic default song\n",
        "    print(\"WARNING: Global features not found. Using a default mock Pop/Rock song profile.\")\n",
        "    your_song_features = {\n",
        "        'bpm': 100.0,\n",
        "        'average_pitch': 60.0,\n",
        "        'pitch_range': 25.0,\n",
        "        'key_stability': 0.80,\n",
        "        'mode_major': 1,\n",
        "        'note_density': 1.5,\n",
        "        'rhythm_variety': 2.0,\n",
        "        'original_file': 'Default Pop/Rock Profile'\n",
        "    }\n",
        "    file_analyzed = your_song_features['original_file']\n",
        "\n",
        "\n",
        "if your_song_features:\n",
        "    # Run the recommendation engine, now requesting 5 songs (k=5)\n",
        "    top_recommendations = recommend_songs(your_song_features, k=5)\n",
        "\n",
        "    print(\"\\n####################################################\")\n",
        "    print(f\"Recommendations for '{file_analyzed}':\")\n",
        "    print(\"####################################################\")\n",
        "\n",
        "    if top_recommendations:\n",
        "        for rec in top_recommendations:\n",
        "            # --- FINAL OUTPUT FORMAT: Title by Artist (Score%) ---\n",
        "            print(f\"- {rec['title']} by {rec['artist']} ({rec['similarity_score']:.0f}%)\")\n",
        "    else:\n",
        "        print(\"Could not find any recommendations.\")"
      ],
      "metadata": {
        "id": "Kg8sdxdQkx3G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}